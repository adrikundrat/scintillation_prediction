{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff0beb56-b3b2-4f3f-b209-d2a5f59d9a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# created with love in cooperation with ASPIS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, plot_precision_recall_curve\n",
    "from sklearn.metrics import fbeta_score, auc, confusion_matrix, classification_report, mean_absolute_error, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b830f9c-4297-4d28-9b56-d03c13198dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fcbd5df-842a-4a44-9d8f-285ca29d08b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(columns=['col', 'epoch', 'eval_v', 'tp', 'fp', 'fn', 'tn', 'p', 'r', 'f1', 'auc-roc', 'auc-pr', 'tss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea7f21b-1d68-4ce3-853c-d938c8a57dda",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"###################\")\n",
    "\n",
    "print(\"# settings\")\n",
    "directory = \"full_to_eval_2\"\n",
    "with open('eval_2.txt', 'a') as the_file:\n",
    "# nastav spravne cesty\n",
    "    for subdir, dirs, files in os.walk(f\"/home/jovyan/data/lightning/adrian/dip/vierka_train/training/%s\"%directory):\n",
    "        if len(files)>0:\n",
    "            a=subdir\n",
    "            f_name = subdir[subdir.index(\"%s/\"%directory):subdir.index(\"/autoreg\")]\n",
    "            config = f_name.split('/')[1]\n",
    "            for file in files:\n",
    "                if 'ch-05' in file:\n",
    "                    saved_model = f\"/home/jovyan/data/lightning/adrian/dip/vierka_train/training/{f_name}/autoreg/%s\"%file\n",
    "                    # skontroluj\n",
    "\n",
    "                    X_test = np.load(f'/home/jovyan/data/lightning/adrian/dip/vierka_train/data-preparation/{f_name}/X_test.npy',allow_pickle=True).item()\n",
    "                    y_test = np.load(f'/home/jovyan/data/lightning/adrian/dip/vierka_train/data-preparation/{f_name}/y_test.npy')\n",
    "\n",
    "                    Phi60_Sig1 = X_test[\"Phi60_Sig1\"]\n",
    "\n",
    "                    print(\"###################\")\n",
    "                    print(\"# load data\")\n",
    "                    # niekedy je cely rok strasne vela na vyhodnotenie \n",
    "                    # zvazit pripadne takyto split - jednotne vsetky experimenty, finalne nastavenie na celom\n",
    "                    y_test = y_test[ :int(len(y_test)/16)]\n",
    "                    Phi60_Sig1 = Phi60_Sig1[ :int(len(Phi60_Sig1)/16)]\n",
    "\n",
    "                    print(\"###################\")\n",
    "                    print(\"# predict\")\n",
    "                    model = keras.models.load_model(saved_model)\n",
    "\n",
    "                    y_pred = model.predict(Phi60_Sig1)\n",
    "\n",
    "                    print(\"###################\")\n",
    "                    print(\"# roc + thresh\")\n",
    "\n",
    "                    y_true = np.where(y_test >= 0.1, 1, 0)\n",
    "                    y_scores = y_pred\n",
    "\n",
    "\n",
    "                    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "                    print(\"AUC:\", roc_auc_score(y_true, y_scores))\n",
    "\n",
    "                    optimal_idx = np.argmax(tpr - fpr)\n",
    "                    optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "                    print(\"Optimal threshold value is:\", optimal_threshold)\n",
    "                    plot_roc_curve(fpr, tpr)\n",
    "\n",
    "                    print(\"###################\")\n",
    "                    print(\"# pr curve\")\n",
    "                    # finalne vykreslim krajsie - ako v notebooku treshold_notebook.ipynb, len to treba stale instalovat kniznice takze zatial takto\n",
    "                    precision, recall, thresholds = precision_recall_curve(y_true,y_pred)\n",
    "                    # plot the roc curve for the model\n",
    "                    no_skill = len(y_true[y_true==1]) / len(y_true)\n",
    "                    pyplot.plot([0,1], [no_skill,no_skill], linestyle='--', label='No Skill')\n",
    "                    pyplot.plot(recall, precision, marker='.', label='Logistic')\n",
    "                    # axis labels\n",
    "                    pyplot.xlabel('Recall')\n",
    "                    pyplot.ylabel('Precision')\n",
    "                    pyplot.legend()\n",
    "                    # show the plot\n",
    "                    pyplot.show()\n",
    "\n",
    "                    print(\"###################\")\n",
    "                    print(\"# evaluation v1\")\n",
    "                    the_file.write(\"\\n###################\")\n",
    "                    the_file.write(\"# evaluation v1\\n\")\n",
    "\n",
    "                    # zakladne vyhodnotenie bez agregacie \n",
    "\n",
    "                    y_pred2 = np.where(y_pred >= optimal_threshold, 1, 0)\n",
    "                    y_test2 = np.where(y_test >= 0.1, 1, 0)\n",
    "\n",
    "                    cm = confusion_matrix(y_test2, y_pred2)\n",
    "\n",
    "                    print(\"Confusion matrix: \\n\" + str(cm))\n",
    "                    print(classification_report(y_test2, y_pred2))\n",
    "                    the_file.write(\"Confusion matrix: \\n\" + str(cm))\n",
    "                    the_file.write(classification_report(y_test2, y_pred2))\n",
    "                    \n",
    "                    print(\"MAE: \", str(mean_absolute_error(y_test, y_pred)), \"\\n\")\n",
    "\n",
    "                    print(\"ROC-AUC: \", str(roc_auc_score(y_test2, y_pred)))\n",
    "                    roc_auc = str(roc_auc_score(y_test2, y_pred))\n",
    "\n",
    "                    precision, recall, _ = precision_recall_curve(y_test2, y_pred)\n",
    "                    print(\"PR-AUC: \", str(auc(recall, precision)), \"\\n\")\n",
    "                    pr_auc = str(auc(recall, precision))\n",
    "\n",
    "                    print(\"F-beta macro: \", str(fbeta_score(y_test2, y_pred2, average='macro', beta=np.inf)))\n",
    "                    f_beta = str(fbeta_score(y_test2, y_pred2, average='macro', beta=np.inf))\n",
    "\n",
    "                    print(\"F1 macro: \", str(f1_score(y_test2, y_pred2, average='macro')), \"\\n\")\n",
    "                    f1_macro = str(f1_score(y_test2, y_pred2, average='macro'))\n",
    "\n",
    "                    #print(\"F-beta weighted: \", str(fbeta_score(y_test2, y_pred2, average='weighted', beta=np.inf)))\n",
    "                    #print(\"F1 weighted: \", str(f1_score(y_test2, y_pred2, average='weighted')))\n",
    "                    df.loc[len(df)]=[config, file, '1', roc_auc, pr_auc, f_beta, f1_macro]\n",
    "\n",
    "\n",
    "                    print(\"###################\")\n",
    "                    print(\"# evaluation v2\")\n",
    "                    # rolling okna kde berieme maximum - toto vyhodnotenie mozeme vo finale asi vynechat \n",
    "\n",
    "                    df_pred = pd.DataFrame(y_pred)\n",
    "                    df_test = pd.DataFrame(y_test)\n",
    "\n",
    "                    df_test[\"y_test_new\"] = df_test[0].rolling(window=5, min_periods=1).max()   \n",
    "                    df_pred[\"y_pred_new\"] = df_pred[0].rolling(window=5, min_periods=1).max()   \n",
    "\n",
    "\n",
    "\n",
    "                    y_true = np.where(df_test[\"y_test_new\"] >= 0.1, 1, 0)\n",
    "                    y_scores = y_pred\n",
    "\n",
    "\n",
    "                    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "                    print(\"AUC:\", roc_auc_score(y_true, y_scores))\n",
    "\n",
    "                    optimal_idx = np.argmax(tpr - fpr)\n",
    "                    optimal_threshold2 = thresholds[optimal_idx]\n",
    "\n",
    "                    print(\"Optimal threshold value is:\", optimal_threshold2)\n",
    "                    plot_roc_curve(fpr, tpr)\n",
    "\n",
    "\n",
    "\n",
    "                    #y_pred2 = df_pred[\"y_pred_new\"] \n",
    "                    #y_test2 = df_test[\"y_test_new\"] \n",
    "                    y_pred2 = np.where(df_pred[\"y_pred_new\"] >= optimal_threshold2, 1, 0)\n",
    "                    y_test2 = np.where(df_test[\"y_test_new\"] >= 0.1, 1, 0)\n",
    "\n",
    "                    cm = confusion_matrix(y_test2, y_pred2)\n",
    "\n",
    "                    print(\"Confusion matrix: \\n\" + str(cm))\n",
    "                    print(classification_report(y_test2, y_pred2))\n",
    "                    print(\"MAE: \", str(mean_absolute_error(y_test, y_pred)), \"\\n\")\n",
    "\n",
    "                    print(\"ROC-AUC: \", str(roc_auc_score(y_test2, y_pred)))\n",
    "                    precision, recall, _ = precision_recall_curve(y_test2, y_pred)\n",
    "                    print(\"PR-AUC: \", str(auc(recall, precision)), \"\\n\")\n",
    "\n",
    "                    print(\"F-beta macro: \", str(fbeta_score(y_test2, y_pred2, average='macro', beta=np.inf)))\n",
    "                    print(\"F1 macro: \", str(f1_score(y_test2, y_pred2, average='macro')), \"\\n\")\n",
    "\n",
    "                    #print(\"F-beta weighted: \", str(fbeta_score(y_test2, y_pred2, average='weighted', beta=np.inf)))\n",
    "                    #print(\"F1 weighted: \", str(f1_score(y_test2, y_pred2, average='weighted')))\n",
    "\n",
    "                    print(\"###################\")\n",
    "                    print(\"# evaluation v3\")\n",
    "                    the_file.write(\"###################\")\n",
    "                    the_file.write(\"# evaluation v3\")\n",
    "                    # aregovane vyhodnocovanie po binarizacii sa berie okno velkosti 6 v ktorom musia byt aspon 2 scintilacie\n",
    "                    # - treba experimentovat s tymito cislami\n",
    "\n",
    "                    df_pred = pd.DataFrame(y_pred)\n",
    "                    df_test = pd.DataFrame(y_test)\n",
    "\n",
    "                    pred_bin = np.where(df_pred[0] >= optimal_threshold, 1, 0)\n",
    "                    test_bin  = np.where(df_test[0] >= 0.1, 1, 0)\n",
    "\n",
    "                    # tu je moznost to menit dala som ze v okne 6 sa ma nachadzat hodnota vacsia ako treshold minimalne 2x\n",
    "                    df_pred[\"pred_bin\"] = pred_bin\n",
    "                    cond = df_pred[\"pred_bin\"].rolling(window=6, min_periods=1).sum().ge(2)  \n",
    "\n",
    "\n",
    "                    df_test[\"test_bin\"] = test_bin\n",
    "                    cond2 = df_test[\"test_bin\"].rolling(window=6, min_periods=1).sum().ge(2) \n",
    "\n",
    "\n",
    "                    df_pred[\"y_pred_new\"] = df_pred[\"pred_bin\"].where(cond).replace(0,1).fillna(0)\n",
    "                    df_test[\"y_test_new\"] = df_test[\"test_bin\"].where(cond2).replace(0,1).fillna(0)\n",
    "\n",
    "\n",
    "                    y_pred2 = df_pred[\"y_pred_new\"] \n",
    "                    y_test2 = df_test[\"y_test_new\"] \n",
    "\n",
    "                    cm = confusion_matrix(y_test2, y_pred2)\n",
    "\n",
    "                    print(\"Confusion matrix: \\n\" + str(cm))\n",
    "                    print(classification_report(y_test2, y_pred2))\n",
    "                    the_file.write(\"Confusion matrix: \\n\" + str(cm))\n",
    "                    the_file.write(classification_report(y_test2, y_pred2))\n",
    "                    \n",
    "                    \n",
    "                    print(\"MAE: \", str(mean_absolute_error(y_test, y_pred)), \"\\n\")\n",
    "\n",
    "                    print(\"ROC-AUC: \", str(roc_auc_score(y_test2, y_pred)))\n",
    "                    roc_auc = str(roc_auc_score(y_test2, y_pred))\n",
    "\n",
    "                    precision, recall, _ = precision_recall_curve(y_test2, y_pred)\n",
    "                    print(\"PR-AUC: \", str(auc(recall, precision)), \"\\n\")\n",
    "                    pr_auc = str(auc(recall, precision))\n",
    "\n",
    "                    print(\"F-beta macro: \", str(fbeta_score(y_test2, y_pred2, average='macro', beta=np.inf)))\n",
    "                    f_beta = str(fbeta_score(y_test2, y_pred2, average='macro', beta=np.inf))\n",
    "\n",
    "                    print(\"F1 macro: \", str(f1_score(y_test2, y_pred2, average='macro')), \"\\n\")\n",
    "                    f1_macro = str(f1_score(y_test2, y_pred2, average='macro'))\n",
    "\n",
    "\n",
    "                    df.loc[len(df)]=[config, file, '3', roc_auc, pr_auc, f_beta, f1_macro]\n",
    "\n",
    "                    #print(\"F-beta weighted: \", str(fbeta_score(y_test2, y_pred2, average='weighted', beta=np.inf)))\n",
    "                    #print(\"F1 weighted: \", str(f1_score(y_test2, y_pred2, average='weighted')))\n",
    "                              \n",
    "\n",
    "df.to_csv('{}.csv'.format(config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f979b6-bdf6-4c51-b69c-b9ea68847ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
